---
title: "simulation_prs_linear"
author: "Tobias Gradinger"
date: "2024-07-22"
---

```{r Setup, include = F}
knitr::opts_chunk$set(include = F)
```

```{r Packages}
library(dplyr)
library(magrittr)
library(ggplot2)
library(pander)
library(ppcor)
library(car)
library(ggpubr)
library(gridExtra)
library(cowplot)
library(patchwork)
library(conflicted)
library(QuantPsyc)
library(MeMoBootR)
#library(png)
```

```{r SETUP clean-up, eval=T}
# remove all objects to start with clean environment
rm(list=ls())
```

```{r SETUP solve function conflicts}
conflicts_prefer(dplyr::filter, dplyr::select, dplyr::n())
```

```{r Functions}
t.report <- function(tt){
  tvalue <- tt$statistic %>% formatC(digits = 2, format = "f")
  pvalue <- tt$p.value %>% formatC(digits = 2, format = "f")
  if (round(tt$parameter, 0) == tt$parameter) {
    df <- tt$parameter
  } else {
    df <- formatC(digits = 2, format = "f")
  }
  if (tt$p.value < 0.0005) {
    pvalue <- " < 0.001" 
  } else { 
    if (tt$p.value < 0.005) {
      pvalue <- paste0(" = ",tt$p.value %>% formatC(digits = 3, format = "f"))
    } else {
      pvalue <- paste0(" = ",tt$p.value %>% formatC(digits = 2, format = "f"))
    }
    } 
  paste0("*t*(",df,") = ",tvalue, ", *p*", pvalue)
}

mean_sd_se.report <- function(df, filtervar, filter, var){
  mean <- df %>% filter (!!filtervar == filter) %>% .[[var]] %>% mean() %>% round(2)
  sd <- df %>% filter (!!filtervar == filter) %>% .[[var]] %>% sd() %>% round(2)
  se <- df %>% filter (!!filtervar == filter) %>% .[[var]] %>% se() %>% round(2)
  
  paste0(filter," mean = ", mean, ", sd = ", sd, ", ", "se = ", se)
}

remove_outliers <- function(data, variables, multiplier = 2) {
  for (variable in variables) {
    Q1 <- quantile(data[[variable]], 0.25, na.rm = TRUE)
    Q3 <- quantile(data[[variable]], 0.75, na.rm = TRUE)
    IQR <- Q3 - Q1
    lower_bound <- Q1 - multiplier * IQR
    upper_bound <- Q3 + multiplier * IQR

    data <- data %>%
      filter(get(variable) >= lower_bound & get(variable) <= upper_bound)
  }
  
  return(data)
}
```

```{r Simulate f(y)=logit of x}
set.seed(123)

# Step 1: Simulate x from a normal distribution
x <- rnorm(100000, mean = 50, sd = 15)
x <- round(x)  # Make x integers
x <- ifelse(x < 1, 1, ifelse(x > 100, 100, x))  # Ensure x is within 1 to 100

# Step 2: Calculate probabilities for y = 1 using a linear function
intercept <- -4.605  # Base probability for y = 1 = 0.01 (logit(p) = log(p/1-p)) = -4.605
slope <- 0.01     # Influence of x on probability

# Linear transformation to calculate the logit
logit <- intercept + slope * x

# Convert logit to probability
prob_y <- exp(logit) / (1 + exp(logit))

# Ensure the overall probability is approximately 1%
#prob_y <- prob_y * (0.01 / mean(prob_y))

# Clip probabilities to be within [0, 1]
prob_y <- pmin(pmax(prob_y, 0), 1)

# Step 3: Sample y using these probabilities
y <- rbinom(length(x), size = 1, prob = prob_y)

# Combine into a dataframe
simulated_data <- data.frame(x = x, y = y)

# Step 4: Split x into quintiles
simulated_data$quintile <- cut(simulated_data$x, 
                               breaks = quantile(simulated_data$x, probs = seq(0, 1, by = 0.1)), 
                               include.lowest = TRUE, 
                               labels = FALSE)

# Step 5: Calculate the percentage of y = 1 and the mean of x for each quintile
quintile_summary <- simulated_data %>%
  group_by(quintile) %>%
  summarize(
    total = n(),
    count_y_1 = sum(y),
    percent_y_1 = (count_y_1 / total) * 100,
    mean_x = mean(x)
  )

# Print the summary
print(quintile_summary)
```

```{r Simulate f(y) = linear(x))}
set.seed(42)

set.seed(42)

# Generate normally distributed x with mean 50 and standard deviation 10
n <- 100000
x <- round(rnorm(n, mean = 50, sd = 10))

# Calculate linear probabilities with a custom scaling to achieve ~1% overall probability of y = 1
prob_y <- (x - min(x)) / (max(x) - min(x)) * 0.02

# Sample y based on the calculated probabilities
y <- rbinom(n, size = 1, prob = prob_y)

# Create a data frame
simulated_data <- data.frame(x = x, y = y, prob_y = prob_y)

# Verify the overall percentage of y = 1
mean(y)

# Split x into quintiles and display the percentage of y = 1 for each quintile
quintile_summary <- simulated_data %>%
  mutate(quintile = ntile(x, 5)) %>%
  group_by(quintile) %>%
  summarize(percent_y_1 = mean(y) * 100,
            mean_x = mean(x))

# Print quintile summary
print(quintile_summary)

```

```{r}
plot_prob_y_x <- ggplot(simulated_data, aes(x = x, y = prob_y)) +
  geom_point(alpha = 0.5, color = "blue") +
  geom_smooth(method = "lm", se = FALSE, color = "red", size = 0.7) +
  labs(title = "Probability of y = 1 vs. x",
       x = "x",
       y = "Probability of y = 1") +
  theme_minimal() +
  theme(axis.title = element_text(face = "bold", size = 10),
        axis.text = element_text(size = 10),
        plot.title = element_text(hjust = 0.5))

# Display the plot
print(plot_prob_y_x)
```

```{r}
p_combined <- ggplot(quintile_summary, aes(x = factor(quintile))) +
  geom_bar(aes(y = percent_y_1), stat = "identity", fill = "skyblue") +
  geom_point(aes(y = mean_x*0.01), color = "red", size = 3) +
  geom_line(aes(y = mean_x*0.01, group = 1), color = "red", size = 1) +
  labs(title = "Percentage of y = 1 and Mean of x for Each Quintile",
       x = "Quintile of x",
       y = "Percentage of y = 1 / Mean of x") +
  theme_minimal() +
  scale_y_continuous(
    name = "Percentage of y = 1",
    sec.axis = sec_axis(~ ., name = "Mean of x")
  ) +
  theme(axis.title.y.right = element_text(color = "red"))

# Display the plot
print(p_combined)
```

```{r}
simulated_data
```


